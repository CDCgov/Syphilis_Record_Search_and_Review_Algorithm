{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Jupyter Notebook: Prioritization of Syphilis Serologies for Investigation (Modernizing the Syphilis Reactor Grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notes to keep in mind when using this notebook:\n",
    "\n",
    "* Please ignore the number on the left (that says \"In [x]\") when running these cells. When we refer to a cell number, look for it in the beginning of the cell body. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### TODO BOARD\n",
    "# edit readme to reflect new contributing: This is a final repository and as such blah blah blah. (keep 2nd paragraph, remove 1st)\n",
    "# reorganize readme, add beautiful diagram"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Cell number 1: This cell is for importing python libraries to support the codes that have been used in this Notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell number 1\n",
    "\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import textwrap\n",
    "import datetime as dt\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "# warning suppression\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Cell number 2: Jupyter Notebook cells output only 1 result by default. Lines 3-4 enable the cell to output all the results as an outcome of the script in the cell. This cell also holds several utility functions for the main algorithm loop. We've also included a convenience function to convert XLSX (excel) files to CSV files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell number 2\n",
    "\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "### Utility Functions\n",
    "\n",
    "# cleans a column of strings by typecasting to str and stripping whitespace\n",
    "def cleanstring(df, column):\n",
    "    df[column] = df[column].astype(str) # converts column items into string\n",
    "    df[column] = [x.strip() for x in df[column]] # removes any whitespace from the strings generated previously\n",
    "\n",
    "# these functions return a dataframe with filtered results and are used to reduce redundancy\n",
    "# probably going to be revisited later\n",
    "\n",
    "def reactive_nTT(df:pd.DataFrame, col:str, R:str, W:str, U:str, P:str) -> pd.DataFrame:\n",
    "    return df[(df[col] != R) & (df[col] != W) & (df[col] != U) & (df[col] != P)];\n",
    "\n",
    "def step3_nonreactive_TT(df:pd.DataFrame, col:str, R:str, W:str, U:str, P:str) -> pd.DataFrame:\n",
    "    return df[(df[col] == R) | (df[col] == W) | (df[col] == U) | (df[col] == P)];\n",
    "\n",
    "def step4_TT(df:pd.DataFrame, col:str, filters:list) -> pd.DataFrame:\n",
    "    return df[(df[col] == filters[0]) | (df[col] == filters[1]) | (df[col] == filters[2]) | (df[col] == filters[3]) | (df[col] == filters[4]) |\n",
    "              (df[col] == filters[5]) | (df[col] == filters[6]) | (df[col] == filters[7]) | (df[col] == filters[8]) | (df[col] == filters[9])];\n",
    "######\n",
    "\n",
    "# converts a given excel file to a csv\n",
    "def excel2csv(file, name):\n",
    "    p = pd.read_excel(file)\n",
    "    p.to_csv(f'{name}.csv', sep=\",\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Cell number 3: This is the script to import and read the CSV file. Please copy/paste the address of your file in place of \"Please enter your file path and file name here.csv\".\n",
    "\n",
    "##### This file is read into a DataFrame: `df_main`.  It may take a while for the data to be read into `df_main`, so please wait for the cell to be fully executed before proceeding. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cell number 3\n",
    "df_main = pd.read_csv(\"data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Cell number 4: Displays the column names of the imported file ( saved as `df_main`) and the first 5 lines of your uploaded dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'ID_Profile', 'ID_FieldRecord', 'CD_Disease',\n",
       "       'DS_DiseaseCategory', 'DateUsedForReport', 'DateUsedForReport_',\n",
       "       'IN_Morbidity', 'CaseClassification', 'CD_Gender', 'Age', 'AgeUnit',\n",
       "       'CD_Disposition', 'DS_Disposition', 'DT_Disposition', 'DT_Disposition_',\n",
       "       'ID_Lab', 'DS_Test', 'DT_Specimen', 'DT_Speciment_',\n",
       "       'DS_QualitativeResult', 'DS_QuantitativeResult'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Cell number 4\n",
    "df_main_columns = df_main.columns\n",
    "df_main.columns = [x.strip() for x in df_main.columns]\n",
    "df_main.columns\n",
    "df_main.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Cell number 5: This changes the column names for the dataframe. The DataFrame might contain more elements than is required for this algorithm. Those column names can be left as is. Please change the corresponding column names for the following data elements to:\n",
    "| Column Name | Data Element |\n",
    "| --- | --- |\n",
    "| `ID_Profile` | Unique identifier for an individual |\n",
    "| `Test` | Name of the test (e.g. VDRL, RPR, TP-AB, FTA-ABS) |\n",
    "| `DT_Specimen` | Date of the above test (specimen collected) |\n",
    "| `QuantitativeResult` | Quantitative result for test (titer) |\n",
    "| `QualitativeResult` | Qualitative result for test |\n",
    "| `CD_Gender` | Gender |\n",
    "| `Age` | Age (in years) |\n",
    "| `Disposition` | Disposition assigned |\n",
    "| `DT_Disposition` | Date the disposition was assigned by the DIS (or the STD program) |\n",
    "\n",
    "_Note: We require that age be in years. Please handle this yourself or email the maintainers for further assistance._\n",
    "\n",
    "##### For example, if the output of cell number 4 is: \n",
    "`['columnA', 'UniqueIdentifier', 'columnB', 'QualitativeResult','DateOfSpecimen', 'columnC', 'QuantitativeResult', 'NameOfTest', 'columnD','Gender',' Age', 'DS_Disposition','DT_Disposition']`\n",
    "\n",
    "##### Your code will be:\n",
    "`df_main.columns = ['columnA', 'ID_Profile', 'columnB', 'QualitativeResult' ,'DT_Specimen', 'columnC', 'QuantitativeResult', 'Test', 'columnD','CD_Gender', 'Age', 'Disposition','DT_Disposition']`\n",
    "\n",
    "##### Put any column renaming in the cell below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'ID_Profile', 'ID_FieldRecord', 'CD_Disease',\n",
       "       'DS_DiseaseCategory', 'DateUsedForReport', 'DateUsedForReport_',\n",
       "       'IN_Morbidity', 'CaseClassification', 'CD_Gender', 'Age', 'AgeUnit',\n",
       "       'CD_Disposition', 'DS_Disposition', 'DT_Disposition', 'DT_Disposition_',\n",
       "       'ID_Lab', 'DS_Test', 'DT_Specimen', 'DT_Speciment_',\n",
       "       'DS_QualitativeResult', 'DS_QuantitativeResult'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'ID_Profile', 'ID_FieldRecord', 'CD_Disease',\n",
       "       'DS_DiseaseCategory', 'DateUsedForReport', 'DateUsedForReport_',\n",
       "       'IN_Morbidity', 'CaseClassification', 'CD_Gender', 'Age', 'AgeUnit',\n",
       "       'CD_Disposition', 'Disposition', 'DT_Disposition', 'DT_Disposition_',\n",
       "       'ID_Lab', 'Test', 'DT_Specimen', 'DT_Speciment_', 'QualitativeResult',\n",
       "       'QuantitativeResult'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Cell number 5\n",
    "df_main.columns\n",
    "df_main.rename(columns={'DS_QualitativeResult':'QualitativeResult', 'DS_QuantitativeResult':'QuantitativeResult', 'DS_Test':'Test', 'DS_Disposition':'Disposition'}, inplace=True)\n",
    "df_main.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Cell number 6: The CSV file does not have date attributes. The script below will assign a python date attribute to this column. The same script can be used for any other date elements. \n",
    "###### **The CSV file must contain date the date in the YYYY-MM-DD format. If it is not possible to create it in this format, please let us know.**\n",
    "###### The final line in this cell creates a new column and assigns the index number of the row to it. This will be used to join on at later stages. If you see output in this cell, please ignore it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cell number 6 \n",
    "\n",
    "# function to convert strings in column `var` in pandas DataFrame `df` to datetime\n",
    "def str2date(df, var, dateformat='%Y-%m-%d'):\n",
    "    cleanstring(df, var)\n",
    "    \n",
    "    # The line below can be adjusted to meet unique formats. For example, if the date appears as MM/DD/YYYY, the following\n",
    "    # format will work: '%m/%d/%Y' Please let us know if you have more complicated date formats.\n",
    "    # Furthermore, the last parameter can be customized in the function call section to change the specific date time to match your dataset\n",
    "    # See the function calls section below for a commented out example of this\n",
    "    df[var] = pd.to_datetime(df[var], format=dateformat) # converts the string to a datetime if it follows YYYY-MM-DD format\n",
    "    \n",
    "\n",
    "# function calls\n",
    "str2date(df_main, 'DT_Specimen')\n",
    "str2date(df_main, 'DT_Disposition')\n",
    "\n",
    "## function call example showing how to process datetimes for DT_Specimen if the format is MM/DD/YYYY\n",
    "# str2date(df_main, 'DT_Specimen', dateformat='%m/%d/%Y')\n",
    "\n",
    "df_main['S_No'] = df_main.index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Cell number 7: The database might default titers as '1:x', the following code removes the '1:' part from it and converts it to an integer. Only use the script below if the quantitative result in the dataframe is not extracted as a number. The script below takes away \"1:\" from, converts it into a number, and converts nan (No value) to 0. Cell number 7.b will execute the cleaning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cell number 7\n",
    "\n",
    "def cleannum(a):\n",
    "    if a == 'nan':\n",
    "        return 0\n",
    "    else:\n",
    "        return (a[2:])\n",
    "\n",
    "def cleanquant(df, var):\n",
    "    \n",
    "    cleanstring(df, var)\n",
    "    df['quanttest'] = df[var].apply(cleannum)\n",
    "    df['quanttest'] = df['quanttest'].astype(int)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1:1         56191\n",
       "1:2         43942\n",
       "1:4         29175\n",
       "1:8         23066\n",
       "1:16        18250\n",
       "1:32        15041\n",
       "1:64        11334\n",
       "1:128        9431\n",
       "1:256        4660\n",
       "1:512        2057\n",
       "1:1024        740\n",
       "1:2048        302\n",
       "1:4096        124\n",
       "1:8192         53\n",
       "1:16384        22\n",
       "1:999999        1\n",
       "Name: QuantitativeResult, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0         328849\n",
       "1          56191\n",
       "2          43942\n",
       "4          29175\n",
       "8          23066\n",
       "16         18250\n",
       "32         15041\n",
       "64         11334\n",
       "128         9431\n",
       "256         4660\n",
       "512         2057\n",
       "1024         740\n",
       "2048         302\n",
       "4096         124\n",
       "8192          53\n",
       "16384         22\n",
       "999999         1\n",
       "Name: quanttest, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# cell number 7.b\n",
    "df_main['QuantitativeResult'].value_counts()\n",
    "# execute function\n",
    "cleanquant(df_main, 'QuantitativeResult')\n",
    "df_main['quanttest'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'ID_Profile', 'ID_FieldRecord', 'CD_Disease',\n",
       "       'DS_DiseaseCategory', 'DateUsedForReport', 'DateUsedForReport_',\n",
       "       'IN_Morbidity', 'CaseClassification', 'CD_Gender', 'Age', 'AgeUnit',\n",
       "       'CD_Disposition', 'Disposition', 'DT_Disposition', 'DT_Disposition_',\n",
       "       'ID_Lab', 'Test', 'DT_Specimen', 'DT_Speciment_', 'QualitativeResult',\n",
       "       'QuantitativeResult', 'S_No', 'quanttest'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "nan         328849\n",
       "1:1          56191\n",
       "1:2          43942\n",
       "1:4          29175\n",
       "1:8          23066\n",
       "1:16         18250\n",
       "1:32         15041\n",
       "1:64         11334\n",
       "1:128         9431\n",
       "1:256         4660\n",
       "1:512         2057\n",
       "1:1024         740\n",
       "1:2048         302\n",
       "1:4096         124\n",
       "1:8192          53\n",
       "1:16384         22\n",
       "1:999999         1\n",
       "Name: QuantitativeResult, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_main.columns\n",
    "df_main['QuantitativeResult'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Cell number 8: If the quantitative result or titer was a number in the data extract and cell number 7 was not required, we change the column name to `quanttest`\n",
    "\n",
    "\n",
    "###### Run Cell number 8 customized to the column headings, labelling the column with titer results (quantitative results) as quanttest, only if cell number 7 was not required"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cell number 8\n",
    "\n",
    "#df_main.columns = ['columnA', 'ID_Profile', 'columnB', 'DS_QualitativeResult','DT_Specimen', 'columnC', 'quanttest', 'DS_Test', 'columnD','CD_Gender','Age_clean']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Cell number 9: As part of data-wrangling, the following script ensures that the values for `ID_Profile`, `QualitativeResult`, and `Test` do not contain any spaces and are in string format.\n",
    "\n",
    "###### The data type displayed should show :\n",
    "| Column Name | Datatype |\n",
    "| --- | --- |\n",
    "| `ID_Profile` | `object` |\n",
    "| `Test` | `object` |\n",
    "| `DT_Specimen` | `datetime64[ns]` |\n",
    "| `QuantitativeResult` | `object` |\n",
    "| `quanttest` | `int32` |\n",
    "| `CD_Gender` | `object` |\n",
    "| `Age_clean` | `int32` |\n",
    "| `Disposition` | `object` |\n",
    "| `DT_Disposition` | `datetime64[ns]` |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0                     int64\n",
       "ID_Profile                    object\n",
       "ID_FieldRecord                 int64\n",
       "CD_Disease                     int64\n",
       "DS_DiseaseCategory            object\n",
       "DateUsedForReport             object\n",
       "DateUsedForReport_            object\n",
       "IN_Morbidity                  object\n",
       "CaseClassification            object\n",
       "CD_Gender                     object\n",
       "Age                           object\n",
       "AgeUnit                       object\n",
       "CD_Disposition                object\n",
       "Disposition                   object\n",
       "DT_Disposition        datetime64[ns]\n",
       "DT_Disposition_               object\n",
       "ID_Lab                        object\n",
       "Test                          object\n",
       "DT_Specimen           datetime64[ns]\n",
       "DT_Speciment_                 object\n",
       "QualitativeResult             object\n",
       "QuantitativeResult            object\n",
       "S_No                           int64\n",
       "quanttest                      int32\n",
       "dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Cell number 9\n",
    "dirty_columns = ['ID_Profile', 'QualitativeResult', 'Test', 'CD_Gender', 'Disposition']\n",
    "for c in dirty_columns:\n",
    "    cleanstring(df_main, c)\n",
    "\n",
    "df_main.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Cell number 10: Removes all tests with no dates (they can't be calculated in the algorithm) and reveals how many rows and columns are there in the DataFrame. The following step is not compulsory, but it ensures that all specimen dates have dates else the program will crash."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Number of Null Dates Before Removal: 7946\n",
      "Shape: (534599, 24)\n",
      "Number of Tests After Null Removal: 113507\n"
     ]
    }
   ],
   "source": [
    "# Cell number 10\n",
    "nulldates = df_main[df_main['DT_Specimen'].isnull()] \n",
    "beforelen = len(np.unique(nulldates['ID_Profile']))\n",
    "nulldates_idx = nulldates.index\n",
    "\n",
    "df_main = df_main.drop(nulldates_idx)\n",
    "afterlen = len(np.unique(df_main['ID_Profile']))\n",
    "\n",
    "# ------ output ------\n",
    "print(f\"\")\n",
    "print(f\"Number of Null Dates Before Removal: {beforelen}\")\n",
    "print(f\"Shape: {df_main.shape}\")\n",
    "print(f\"Number of Tests After Null Removal: {afterlen}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Cell number 11: Creating a DataFrame for running the algorithm with only the essential columns. Since we select the core data elements, we remove duplicates (same person, same test, same result, same day). The row index is created as a separate column. This `index_no` will be used to join the rest of the data elements for analysis later on\n",
    "###### We display the number of rows and columns in this DataFrame. There should be 10 columns, the rows depend on how big the dataset is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell number 11\n",
    "\n",
    "df_main_dd = df_main[['ID_Profile','Test','DT_Specimen','quanttest','QualitativeResult','DT_Disposition']]\n",
    "df_main_dd = df_main_dd.drop_duplicates()\n",
    "df_main_dd['index_no'] = df_main_dd.index\n",
    "\n",
    "df_main_dd = df_main_dd.merge(df_main, left_on = 'index_no', right_on = 'S_No', how = 'left')\n",
    "\n",
    "# df_main_dd drops invalid tests with no assigned date \n",
    "# if there is an error, see below\n",
    "df_main_dd = df_main_dd[['ID_Profile_x', 'Test_x', 'DT_Specimen_x', 'quanttest_x',\n",
    "                         'QualitativeResult_x','DT_Disposition_x', 'index_no', 'CD_Gender',\n",
    "                         'Disposition', 'Age']]\n",
    "\n",
    "\n",
    "df_main_dd.columns = ['ID_Profile','Test','DT_Specimen','quanttest','QualitativeResult', 'DT_Disposition','index_no','CD_Gender', 'Disposition', 'Age']\n",
    "\n",
    "#if there is an error:\n",
    "    #It could be because the column names did not match\n",
    "    #In a separate cell, please run\n",
    "    #df_main_dd.dtypes\n",
    "    #df_main_dd.columns\n",
    "    \n",
    "    #under the comment above, please insert how the column name appears in your output in place of these fields above:\n",
    "    #['ID_Profile_x', 'DS_Test_x', 'DT_Specimen_x', 'quanttest_x',\n",
    "    #'DS_QualitativeResult_x', 'index_no', 'CD_Gender',\n",
    "    #'DS_Disposition', 'Age_clean']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(478588, 10)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Index(['ID_Profile', 'Test', 'DT_Specimen', 'quanttest', 'QualitativeResult',\n",
       "       'DT_Disposition', 'index_no', 'CD_Gender', 'Disposition', 'Age'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "ID_Profile                   object\n",
       "Test                         object\n",
       "DT_Specimen          datetime64[ns]\n",
       "quanttest                     int32\n",
       "QualitativeResult            object\n",
       "DT_Disposition       datetime64[ns]\n",
       "index_no                      int64\n",
       "CD_Gender                    object\n",
       "Disposition                  object\n",
       "Age                          object\n",
       "dtype: object"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This cell simply prints the dimension of the dataset as well as the column names. \n",
    "# Feel free to use this cell to debug the previous cell.\n",
    "df_main_dd.shape\n",
    "df_main_dd.columns\n",
    "df_main_dd.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Cell number 12: This is were we define all of our variables. This ensures that we don't have to modify the codes everytime and can just make some adjustments here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell number 12 \n",
    "\n",
    "#Step 7 allows for a cut-off date for titers since we found that titers can be from a long time ago and should not be compared.\n",
    "#This can be modified anytime. We define the duration as 'DaysBetweenTests'\n",
    "DaysBetweenTests = 365\n",
    "\n",
    "#Step 7 quantifies what should be considered a high titer, given that the previous test is much older\n",
    "#This can be modified anytime. We define the titer cutoff as 'TiterCutOff'\n",
    "TiterCutOff = 32\n",
    "\n",
    "#'Female' maybe coded in many foms, please assign the exact variable as it is in your DataFrame\n",
    "Female = 'F'\n",
    "\n",
    "#Step 7 also considers female of reproductive age, to prevent congenital syphilis. We have set the cut-off age as 50\n",
    "#This can be modified anytime. We define the age as 'FemaleAge'\n",
    "FemaleAge = 50\n",
    "\n",
    "#Step 7 was added, in part, to prevent congenital syphilis. For the general population, older titer is considered > 1year\n",
    "#For females of reproductive age, we consider the duration as 180 days and high titer as more than 1:9\n",
    "#This can be modified anytime. We define the duration as 'FemaleDaysBetweenTests' and the titer as 'FemaleTiterCutOff'\n",
    "FemaleDaysBetweenTests = 180\n",
    "FemaleTiterCutOff = 8\n",
    "\n",
    "#Step 5: We found that if patient was not previously treated, their titer might not change and can be reached now\n",
    "#Please assign the exact disposition that the DIS had assigned corresponding to an individual who was infected but not treated\n",
    "disposition_InfNotTx = 'Infected, Not Treated'\n",
    "#Please assign the exact disposition that the DIS had assigned corresponding to an individual who was uable to be located\n",
    "unable_to_locate = 'Unable to Locate'\n",
    "#Please assign the exact disposition that the DIS had assigned corresponding to an individual who was out of jurisdiction\n",
    "OOJ = 'Administrative Closure OOJ'\n",
    "\n",
    "# Please assign values to the corresponding variable as it appears in your dataframe:\n",
    "#R is for reactive tests\n",
    "R = 'R'\n",
    "#W is for weakly positive/reactive tests\n",
    "W = 'W'\n",
    "#U is for unknown\n",
    "U = 'U'\n",
    "#P is for positive. RAPID tests seem to be assigned this qualitative result\n",
    "P = 'P'\n",
    "#N is for negative tests\n",
    "N = 'N'\n",
    "\n",
    "#Please assign how each non-Treponemal Test is coded in your dataframe. ONLY these 5 tests will be considered as NTTs.\n",
    "RPR = 'RPR'\n",
    "VDRL = 'VDRL'\n",
    "CSF_VDRL = 'CSF-VDRL'\n",
    "RPR_CordBlood = 'RPR Cord Blood'\n",
    "TRUST = 'TRUST'\n",
    "\n",
    "#Please assign how each Treponemal Test is coded in your dataframe. ONLY these10 tests will be considere as TTs.\n",
    "FTA_ABS = 'FTA-ABS'\n",
    "IgG_EIA = 'IgG EIA'\n",
    "TP_AB = 'TP-AB'\n",
    "TP_PA = 'TP-PA'\n",
    "RAPID = 'RAPID'\n",
    "EIA = 'EIA'\n",
    "MHATP = 'MHATP'\n",
    "FTA_IgG = 'FTA-IgG'\n",
    "CIA = 'CIA (CLIA)'\n",
    "TPHA = 'TPHA'\n",
    "\n",
    "#This defines all the Treponemal Tests used for filtering the dataframe in the main loop.\n",
    "tests = [FTA_ABS, IgG_EIA, TP_AB, TP_PA, RAPID, EIA, MHATP, FTA_IgG, CIA, TPHA]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Algorithm to Prioritize Reactive Non-Treponemal Tests Reported to Health Departments for Investigating Suspected Cases of Syphilis\n",
    "\n",
    "![algorithm diagram](algorithm_manuscript_revised.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: select only reactive Non-Treponemal Tests (NTT)\n",
    "#### Cell number 13 selects the tests for Step 1 in the algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cell number 13\n",
    "dfm_6m_ntt = df_main_dd[(df_main_dd['Test'] == RPR) | (df_main_dd['Test'] == VDRL) | (df_main_dd['Test'] == CSF_VDRL)| (df_main_dd['Test'] == RPR_CordBlood)|(df_main_dd['Test']==TRUST)]\n",
    "dfm_6m_ntt = dfm_6m_ntt[(dfm_6m_ntt['QualitativeResult'] == R) | (dfm_6m_ntt['QualitativeResult'] == W) | (dfm_6m_ntt['QualitativeResult'] == U)]\n",
    "dfm_6m_ntt = [group[group['DT_Specimen'] == group['DT_Specimen'].max()] for name , group in dfm_6m_ntt.groupby(\"ID_Profile\")]\n",
    "dfm_6m_ntt = pd.concat(dfm_6m_ntt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RPR               117892\n",
       "VDRL                 993\n",
       "CSF-VDRL             136\n",
       "RPR Cord Blood        17\n",
       "TRUST                  4\n",
       "Name: Test, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(119042, 10)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array(['1000059', '1000286', '1000370', ..., '999856', '999938', '999940'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfm_6m_ntt['Test'].value_counts()\n",
    "dfm_6m_ntt.shape\n",
    "np.unique(dfm_6m_ntt['ID_Profile'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cell number 13.1. We want to identify the first test in the latest DT_Disposition (episode of disease). Ideally, we would want to assign a disposition to this first test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "73332"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#13.1\n",
    "list1 = np.unique(dfm_6m_ntt['ID_Profile'])\n",
    "len(list1)\n",
    "df_first_test = pd.DataFrame(columns=['ID_Profile','Test','DT_Specimen','quanttest','QualitativeResult','CD_Gender', 'Age', 'DT_Disposition', 'index_no'])\n",
    "\n",
    "for i in list1:\n",
    "    IncTest = dfm_6m_ntt[dfm_6m_ntt['ID_Profile']==i]\n",
    "    time_IncTest = IncTest['DT_Disposition']\n",
    "    time_IncTest = time_IncTest.values[0]\n",
    "    \n",
    "    df_all = df_main[df_main['ID_Profile'] == i]\n",
    "    df_all = df_all[(df_all['Test'] == RPR) | (df_all['Test'] == VDRL) | (df_all['Test'] == CSF_VDRL) | (df_all['Test'] == RPR_CordBlood) | (df_all['Test'] == TRUST)]\n",
    "    df_sameDT = df_all[df_all['DT_Disposition'] == time_IncTest]\n",
    "    df_earliestTest = [group[group['DT_Specimen'] == group['DT_Specimen'].min()] for name , group in df_sameDT.groupby(\"ID_Profile\")]\n",
    "    \n",
    "    # skips to the next profile if its group doesn't exist\n",
    "    if not df_earliestTest:\n",
    "        continue\n",
    "    \n",
    "    df_earliestTest = pd.concat(df_earliestTest)\n",
    "    df_first_test=df_first_test.append(df_earliestTest)   \n",
    "\n",
    "df_first_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RPR         2744\n",
       "VDRL          16\n",
       "CSF-VDRL       2\n",
       "Name: Test, dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(2762, 25)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfm_6m_ntt = df_first_test\n",
    "\n",
    "dfm_6m_ntt['Test'].value_counts()\n",
    "dfm_6m_ntt.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Cell number 14: A list (`profile_list`) is created with distinct unique identifiers. This profile list is used to loop in the program. \n",
    "##### A single unique identifier (`ID_Profile`) or a subset can be run by creating a list of the subset as `profile_list`. This is especially useful to debug the process and view a specific subset instead of running the entire dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['1000059', '1000286', '1000370', ..., '110136', '1101379',\n",
       "       '1101427'], dtype=object)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "1500"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cell number 14\n",
    "profile_list = dfm_6m_ntt['ID_Profile'].unique()\n",
    "profile_list\n",
    "len(profile_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### An example of cell 14.1 to run a fraction of the dataset (for e.g. a cut-off date) instead of the entire dataset. This will be useful to see if there are any bugs or issues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cell number 14.1\n",
    "profile_list = profile_list[:100]\n",
    "len(profile_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#baseline_date = pd.to_datetime('20190318', format='%Y%m%d') #---->change the date within the '' to what you'd like\n",
    "#baseline_date\n",
    "#df_main_6m_ntt = df_main_dd[df_main_dd['DT_Specimen'] >= baseline_date]\n",
    "\n",
    "#df_main_6m_ntt = df_main_dd[(df_main_dd['DS_Test'] == RPR) | (df_main_dd['DS_Test'] == VDRL)|(df_main_dd['DS_Test']==CSF_VDRL)|(df_main_dd['DS_Test']==RPR_CordBlood)]\n",
    "#df_main_6m_ntt = df_main_6m_ntt[(df_main_6m_ntt['DS_QualitativeResult']==R) | (df_main_6m_ntt['DS_QualitativeResult']==W) | (df_main_6m_ntt['DS_QualitativeResult']==U)]\n",
    "#df_main_6m_ntt = [group[group['DT_Specimen'] == group['DT_Specimen'].max()] for name , group in df_main_6m_ntt.groupby(\"ID_Profile\")]\n",
    "#df_main_6m_ntt = pd.concat(df_main_6m_ntt)\n",
    "\n",
    "#df_main_6m_ntt['DS_Test'].value_counts()\n",
    "#df_main_6m_ntt.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## All of the code for the algorithm is below in cell number 1\n",
    "### Each loop corresponding to the Step number in the algorithm is assigned that loop number.\n",
    "### Apart from the disposition assigned in the algorithm, tests are also assigned the exact decision point (for debugging and testing).\n",
    "### Steps are numbered and commented at every decision node. In case there is an issue with the code, we can print each step to determine where the problem lies.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "dispo_type = 0\n",
    "col1 = ['ID_Profile','Test','DT_Specimen','quanttest','QualitativeResult','CD_Gender', 'Age']\n",
    "col2 = col1.copy()\n",
    "col2.append('index_no')\n",
    "\n",
    "# final dataframe which is written to a file at the end\n",
    "df_complete_merged = pd.DataFrame(columns = ['ID_Profile', 'Test_x', 'DT_Specimen_x', 'quanttest_x',\n",
    "       'QualitativeResult_x', 'CD_Gender_x', 'Age_x', 'index_no',\n",
    "       'algo_dispo', 'dispo', 'dis_type', 'Test_y', 'DT_Specimen_y',\n",
    "       'quanttest_y', 'QualitativeResult_y', 'CD_Gender_y', 'Age_y'])\n",
    "\n",
    "#1111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111\n",
    "for profile_id in profile_list:\n",
    "    #profile_id\n",
    "    count = count+1\n",
    "    sero = 0 \n",
    "    algo_dispo = 'NA'\n",
    "    al_dis = 'NA'\n",
    "    test_tocompare = pd.DataFrame(columns = col1)\n",
    "    test_incoming = pd.DataFrame(columns = col2)\n",
    "    \n",
    "    #Dataframe df_incoming_test isolates the tests for that particular profile_id.\n",
    "    #We will identify the test that should be assigned a disposition  from this \n",
    "    df_incoming_test = dfm_6m_ntt[dfm_6m_ntt['ID_Profile'] == profile_id]\n",
    "\n",
    "########### This is taking in the reactive nontreponemal tests. We intend to assign a disposition to these tests, whether to administratively close or open for investigation########\n",
    "    \n",
    "    #We first select the latest test as 'test_incoming', we will assign a disposition to this test\n",
    "    if len(df_incoming_test.index) > 1:\n",
    "        incoming_test = [group[group['DT_Specimen'] == group['DT_Specimen'].max()] for name , group in df_incoming_test.groupby(\"ID_Profile\")]\n",
    "        test_incoming = pd.concat(incoming_test)\n",
    "    else:\n",
    "        test_incoming = df_incoming_test\n",
    "\n",
    "    #################### We identified test_incoming as THE TEST to assign this disposition ###################\n",
    "\n",
    "\n",
    "    #time_of_test is the time the specimen was collected for 'test_incoming', it will be used for decision logic below\n",
    "    time_of_test = pd.to_datetime(test_incoming['DT_Specimen'].values[0])\n",
    "\n",
    "    \n",
    "    #!!!!!!!!!! df_match contains the entire dataset; we use this to identify the matches for the test !!!!!!\n",
    "    df_match = df_main_dd[df_main_dd['ID_Profile'] == profile_id]\n",
    "    \n",
    "    #Creating a dataframe 'df_match_all' which has all the tests before 'time_of_test' for each individual ID_Profile\n",
    "    df_match_all = df_match[df_match['DT_Specimen'] < time_of_test]\n",
    "    \n",
    "    #Creating a dataframe 'TT_tocompare' which has all the nonreactive treponemal tests before for each individual ID_Profile\n",
    "    TT_tocompare = df_match\n",
    "    TT_tocompare = reactive_nTT(TT_tocompare, 'QualitativeResult', R, W, U, P) \n",
    "    TT_tocompare = step4_TT(TT_tocompare, 'Test', tests)\n",
    "    \n",
    "    TT_tocompare = TT_tocompare[~(TT_tocompare['DT_Specimen'] > time_of_test)]\n",
    "    \n",
    "    #Creating a marker step_2b(REVISIT). It is 1 when 2.b condition is met, otherwise it is 0.\n",
    "    step_3b = 0\n",
    "    csf_cord = test_incoming[(test_incoming['Test'] == CSF_VDRL) | (test_incoming['Test'] == RPR_CordBlood)]\n",
    "    \n",
    "    #########################Step 222222222222222222222222222222222222222222222\n",
    "    ######################As per Step 2: current titer CSF or cord blood? #########################\n",
    "    if csf_cord.empty is False:\n",
    "        csf_cord = [group[group['quanttest'] == group['quanttest'].max()] for name , group in csf_cord.groupby(\"ID_Profile\")]\n",
    "        test_incoming = pd.concat(csf_cord)\n",
    "        test_incoming = test_incoming.iloc[[0]]\n",
    "        algo_dispo = 'Open: CSF/Cord'\n",
    "        al_dis = 'Open'\n",
    "        dispo_type = '2.b'\n",
    "    \n",
    "    else:\n",
    "        \n",
    "        #333333333333333333333333333333333333333333333333333333333333333333333333333333\n",
    "        if TT_tocompare.empty is False:\n",
    "            #If there is a Non-Reactive TT, we identify the latest test\n",
    "            TT_tocompare = [group[group['DT_Specimen'] == group['DT_Specimen'].max()] for name , group in TT_tocompare.groupby(\"ID_Profile\")]\n",
    "            TT_tocompare = pd.concat(TT_tocompare)  \n",
    "            positive_TT = df_match\n",
    "            \n",
    "            positive_TT = step3_nonreactive_TT(positive_TT, 'QualitativeResult', R, W, U, P)\n",
    "            positive_TT = step4_TT(positive_TT, 'Test', tests)\n",
    "            positive_TT = positive_TT[~(positive_TT['DT_Specimen'] > time_of_test)]\n",
    "        \n",
    "            negative_TT = positive_TT[(positive_TT['QualitativeResult'] != R)]\n",
    "            negative_TT = negative_TT[(positive_TT['QualitativeResult'] != W)]\n",
    "            negative_TT = negative_TT[(positive_TT['QualitativeResult'] != U)]\n",
    "            negative_TT = negative_TT[(positive_TT['QualitativeResult'] != P)]\n",
    "            positive_TT = positive_TT[~(positive_TT['QualitativeResult'].isin(negative_TT['QualitativeResult']))]\n",
    "        \n",
    "            if len(positive_TT)>1:    \n",
    "                if (((pd.to_datetime(time_of_test) - pd.to_datetime(positive_TT['DT_Specimen'].values[0]))/np.timedelta64(1,'D')) <= 14):\n",
    "                    positive_TT = positive_TT.iloc[[0]]\n",
    "                    \n",
    "                \n",
    "            ##################### Step 3 in the algorithm 3333333333333333333333333333333333333\n",
    "            ################# Non-reactive TT in last 14 days with no reactive TT reported within this duration\n",
    "                        \n",
    "            if (positive_TT.empty is True) & (((pd.to_datetime(time_of_test) - pd.to_datetime(TT_tocompare['DT_Specimen'].values[0]))/np.timedelta64(1,'D')) <= 14): #& (((pd.to_datetime(time_of_test) - pd.to_datetime(TT_tocompare['DT_Specimen'].values[0]))/np.timedelta64(1,'D')) >=0):\n",
    "                #As per step 3: Non-Reactive Treponemal Test <= 14 Days Prior to Treponemal Test? ############################\n",
    "                algo_dispo = 'Close: TT_14d'\n",
    "                al_dis = 'Close'\n",
    "                dispo_type = '3.b'\n",
    "                test_tocompare = TT_tocompare.iloc[[0]]\n",
    "                test_incoming = test_incoming.iloc[[0]]\n",
    "            # if serology meets this condition then 'step_3b' is assigned  a value '1' and exits the next loop ########\n",
    "                step_3b = 1\n",
    "           \n",
    "        ############################### If step 3 was not met ################################     \n",
    "        if step_3b == 0:\n",
    "                       \n",
    "            # test_incoming := latest test with disposition to assign to\n",
    "\n",
    "            prior_test_date = df_match_all['DT_Specimen'].max()\n",
    "            prior_test = df_match_all[df_match_all['DT_Specimen'] == prior_test_date]\n",
    "            prior_test = step4_TT(prior_test, 'Test', tests)\n",
    "            prior_test = reactive_nTT(prior_test, 'QualitativeResult', R, W, U, P)\n",
    "            \n",
    "            ########################## Step 4 in the algorithm 4444444444444444444444444444444444444444444\n",
    "            ###################### Penultimate test has a negative treponemal test ###################\n",
    "            if prior_test.empty is False:\n",
    "                test_tocompare = prior_test.iloc[[0]]    \n",
    "                test_incoming = test_incoming.iloc[[0]]\n",
    "                algo_dispo = 'Open: Pen_N_TT'\n",
    "                al_dis = 'Open'\n",
    "                dispo_type = '4.b'\n",
    "            else:    \n",
    "\n",
    "                \n",
    "                ############################ Step 5 in the algorithm 555555555555555555555555555555555555555\n",
    "                #################### Does patient have Prior Syphilis Non-Treponemal Test? ####################\n",
    "                \n",
    "                #'df_match_ntt' creates a dataframe for Non_Treponemal Tests\n",
    "                df_match_ntt = df_match_all[(df_match_all['Test'] == RPR) | (df_match_all['Test'] == VDRL)]\n",
    "                \n",
    "                ## Step 5 logic found in the else statement below near the end of loop close:\n",
    "                \n",
    "                if df_match_ntt.empty is False:\n",
    "                    incoming_test = test_incoming[test_incoming['quanttest']>0]\n",
    "                    if len(incoming_test) > 0:\n",
    "                        incoming_test = [group[group['quanttest'] == group['quanttest'].max()] for name , group in incoming_test.groupby(\"ID_Profile\")]\n",
    "                        incoming_test = pd.concat(incoming_test)\n",
    "                    \n",
    "                    ########################## Step 6 in the algorithm 66666666666666666666666666666666666\n",
    "\n",
    "                    if len(df_match_all) > 1:\n",
    "                        previouslynotx = [group[group['DT_Specimen'] == group['DT_Specimen'].max()] for name , group in df_match_all.groupby(\"ID_Profile\")]\n",
    "                        previouslynotx = pd.concat(previouslynotx)\n",
    "                        previouslynotx = previouslynotx[(previouslynotx['Disposition'] == unable_to_locate) | (previouslynotx['Disposition'] == unable_to_locate) | (previouslynotx['Disposition'] == OOJ) | (previouslynotx['Disposition'] == disposition_InfNotTx)]\n",
    "                    else:\n",
    "                        previouslynotx = df_match_all[(df_match_all['Disposition'] == unable_to_locate) | (df_match_all['Disposition'] == unable_to_locate) | (df_match_all['Disposition'] == OOJ) | (df_match_all['Disposition'] == disposition_InfNotTx)]\n",
    "                    if len(previouslynotx)>1:\n",
    "                        previouslynotx = [group[group['DT_Specimen'] == group['DT_Specimen'].max()] for name , group in previouslynotx.groupby(\"ID_Profile\")]\n",
    "                        previouslynotx = pd.concat(previouslynotx)\n",
    "                   \n",
    "                    ########################## Previous disposition 'infected, not treated': yes ################\n",
    "                    if previouslynotx.empty is False:\n",
    "                        algo_dispo = 'Open: PrevNoTx'\n",
    "                        al_dis = 'Open'\n",
    "                        dispo_type = '6.b'\n",
    "                        previouslynotx = previouslynotx[['ID_Profile','Test','DT_Specimen','quanttest','QualitativeResult']]\n",
    "                        test_tocompare = previouslynotx.iloc[[0]]\n",
    "                        test_incoming = test_incoming.iloc[[0]]\n",
    "\n",
    "                    else:\n",
    "                        ########################## Step 7 in the algorithm 77777777777777777777777777777777777\n",
    "                        \n",
    "                        ## Step 7 logic found in the else statement below near the end of loop close:\n",
    "                        if incoming_test.empty is False:\n",
    "                            test_incoming = incoming_test\n",
    "                            latest_titer = df_match_ntt[df_match_ntt['quanttest'] > 0]\n",
    "                            \n",
    "                            #@@@@@@ START: these codes :-\n",
    "                            ## 1: find previous titer to compare to current serology\n",
    "                            ## 2: any negative serology prior to current serology to look for serconversion\n",
    "                            if len(latest_titer) > 0:\n",
    "                                latest_titer = [group[group['DT_Specimen'] == group['DT_Specimen'].max()] for name , group in latest_titer.groupby(\"ID_Profile\")]\n",
    "                                # 'latest_titer' identifies the previous titer, before the current reported serology\n",
    "                                latest_titer = pd.concat(latest_titer)\n",
    "                                seroconversion = df_match_ntt[df_match_ntt['QualitativeResult'] == N]\n",
    "                                seroconversion = seroconversion[seroconversion['DT_Specimen']>=latest_titer['DT_Specimen'].values[0]]\n",
    "                            else:\n",
    "                                last_titer = df_match_ntt[df_match_ntt['QualitativeResult']!=N]\n",
    "\n",
    "                                if len(last_titer) > 0:\n",
    "                                    last_titer = [group[group['DT_Specimen'] == group['DT_Specimen'].max()] for name , group in last_titer.groupby(\"ID_Profile\")]\n",
    "                                    last_titer = pd.concat(last_titer)\n",
    "                                    seroconversion = df_match_ntt[df_match_ntt['QualitativeResult'] == N]\n",
    "                                    seroconversion = seroconversion[seroconversion['DT_Specimen'] >= last_titer['DT_Specimen'].values[0]]\n",
    "                                else:\n",
    "                                    seroconversion = df_match_ntt[df_match_ntt['QualitativeResult'] == N]\n",
    "\n",
    "                            if len(seroconversion) > 1:\n",
    "                                seroconversion = [group[group['DT_Specimen'] == group['DT_Specimen'].max()] for name , group in seroconversion.groupby(\"ID_Profile\")]\n",
    "                                seroconversion = pd.concat(seroconversion)\n",
    "                                seroconversion = seroconversion.iloc[[0]]\n",
    "                            #@@@@@@ END: these codes :-\n",
    "                            ## 1: find previous titer to compare to current serology\n",
    "                            ## 2: any negative serology prior to current serology to look for serconversion\n",
    "\n",
    "                            ########################## Step 8 in the algorithm 8888888888888888888888888888888888888\n",
    "                            if latest_titer.empty is False:\n",
    "                                ############## (Current titer>1:32 AND previous titer >1 year) #####################\n",
    "                                ##############                           OR                    #####################\n",
    "                                ########### (Female < 50y AND titer > 1:8 AND previous titer > 6m) #################\n",
    "                                \n",
    "                                duration = (pd.to_datetime(time_of_test) - pd.to_datetime(latest_titer['DT_Specimen'].values[0]))/np.timedelta64(1,'D')\n",
    "                                sero2 = (pd.to_datetime(seroconversion['DT_Specimen']) - pd.to_datetime(latest_titer['DT_Specimen'].values[0]))/np.timedelta64(1,'D')\n",
    "\n",
    "                                if (test_incoming['CD_Gender'].values[0]==Female) & (duration >= FemaleDaysBetweenTests) & (int(test_incoming['Age'].values[0]) < FemaleAge) & (test_incoming['quanttest'].values[0] > FemaleTiterCutOff):\n",
    "                                    algo_dispo = 'Open: ModCrit'\n",
    "                                    al_dis = 'Open'\n",
    "                                    dispo_type = '8.b2'\n",
    "                                    test_tocompare = latest_titer.iloc[[0]]    \n",
    "                                    test_incoming = test_incoming.iloc[[0]]\n",
    "                                elif (duration >= DaysBetweenTests) & (test_incoming['quanttest'].values[0]>TiterCutOff):\n",
    "                                    algo_dispo = 'Open: ModCrit'\n",
    "                                    al_dis = 'Open'\n",
    "                                    dispo_type = '8.b1'\n",
    "                                    test_tocompare = latest_titer.iloc[[0]]\n",
    "                                    test_incoming = test_incoming.iloc[[0]]\n",
    "                                \n",
    "                                else:\n",
    "                                    ##################### Step 9 in the algorithm 999999999999999999999999999999999999\n",
    "                                    ##################### >=4-fold Titer Increase: Yes ###############################\n",
    "                            \n",
    "                                    if test_incoming['quanttest'].values[0] >= ((latest_titer['quanttest'].values[0]*2)*2):\n",
    "                                        algo_dispo = 'Open: 4f'\n",
    "                                        al_dis = 'Open'\n",
    "                                        dispo_type = '9.b1'\n",
    "                                        test_tocompare = latest_titer.iloc[[0]]\n",
    "                                        test_incoming = test_incoming.iloc[[0]]\n",
    "                                    else:\n",
    "                                        ################# Step 10 in the algorithm 1010101010101010101010101010101010\n",
    "                                        \n",
    "                                        if (test_incoming['QualitativeResult'].values[0]==R) & seroconversion.empty is False:\n",
    "                                            ################# Check for serocoversion ###################################\n",
    "                                            algo_dispo = 'Open: SeroConv'\n",
    "                                            al_dis = 'Open'\n",
    "                                            dispo_type = '10.b1'\n",
    "                                            test_tocompare = seroconversion\n",
    "                                            test_incoming = test_incoming.iloc[[0]]\n",
    "\n",
    "                                        else:\n",
    "                                            ################# No seroconversion, close: no 4-fold increase ###############\n",
    "                                            algo_dispo = 'Close: 4f'\n",
    "                                            al_dis = 'Close'\n",
    "                                            dispo_type = '10.a1'\n",
    "                                            test_incoming = test_incoming[test_incoming['QualitativeResult'] == R]\n",
    "                                            test_incoming = test_incoming.iloc[[0]]\n",
    "                                            test_tocompare = latest_titer.iloc[[0]]\n",
    "                                        ############ Step 10 close loop 1010101010101010101010101010101010101010\n",
    "                                    ################ Step 9 close loop 999999999999999999999999999999999999999999\n",
    "                            \n",
    "                            #################### if there were no titers reported previously#####################\n",
    "                            else:\n",
    "                                \n",
    "                                ################## if serconversion is present ############################\n",
    "                                if (test_incoming['QualitativeResult'].values[0]==R) & seroconversion.empty is False:\n",
    "                                    #As per step Non-Treponemal Seroconversion: Yes **********************\n",
    "                                    algo_dispo = 'Open: SeroConv'\n",
    "                                    al_dis = 'Open'\n",
    "                                    dispo_type = '10.b2'\n",
    "                                    test_tocompare = seroconversion.iloc[[0]]\n",
    "                                    test_incoming = test_incoming.iloc[[0]]\n",
    "                                    \n",
    "                                ################## no seroconversion, no previous titer ############################   \n",
    "                                elif last_titer.empty is False:\n",
    "                                    algo_dispo = 'Open: NoPrevTi'\n",
    "                                    al_dis = 'Open'\n",
    "                                    dispo_type = '9.b2'\n",
    "                                    test_tocompare = last_titer.iloc[[0]]\n",
    "                                    test_incoming = test_incoming.iloc[[0]]\n",
    "                                    test_incoming = test_incoming.iloc[[0]]\n",
    "                                \n",
    "                                ################## does not meet 4-fold increase criteria ##########################\n",
    "                                else:\n",
    "                                    \n",
    "                                    algo_dispo = 'Close: 4f'\n",
    "                                    al_dis = 'Close'\n",
    "                                    dispo_type = '10.a2'\n",
    "                                    test_incoming = test_incoming[test_incoming['QualitativeResult'] == R]\n",
    "                                    test_incoming = test_incoming.iloc[[0]]\n",
    "                                    test_tocompare = latest_titer.iloc[[0]]\n",
    "                                    \n",
    "                            ####################### Step 8 close loop 888888888888888888888888888888888888888888\n",
    "                        ######################## Step 7 in the algorithm#############################\n",
    "                        #######################  Quantitative titer reported on current serology? ####################\n",
    "                        else:\n",
    "                            algo_dispo = 'Open: NoC_NTT'\n",
    "                            al_dis = 'Open'\n",
    "                            dispo_type = '7.a'\n",
    "                            test_incoming = test_incoming.iloc[[0]]\n",
    "\n",
    "                        ########################### Step 7 close loop 77777777777777777777777777777777777777777\n",
    "                    ############################### Step 6 close loop 66666666666666666666666666666666666666666\n",
    "                ######################## Step 5 in the algorithm#############################\n",
    "                #######################  Does patient have Prior Syphilis Non-Treponemal Test? ####################\n",
    "                \n",
    "                else:\n",
    "                    algo_dispo = 'Open: NoM'\n",
    "                    al_dis = 'Open'\n",
    "                    dispo_type = '5.a'\n",
    "                    test_incoming = [group[group['quanttest'] == group['quanttest'].max()] for name , group in test_incoming.groupby(\"ID_Profile\")]\n",
    "                    test_incoming = pd.concat(test_incoming)\n",
    "                    test_incoming = test_incoming.iloc[[0]]\n",
    "\n",
    "                #################################### Step 5 close loop 5555555555555555555555555555555555555555\n",
    "            ######################################## Step 4 close loop 4444444444444444444444444444444444444444\n",
    "        ############################################ Step 3 close loop 3333333333333333333333333333333333333333\n",
    "    ################################################ Step 2 close loop 2222222222222222222222222222222222222222\n",
    "    test_incoming['algo_dispo'] = algo_dispo\n",
    "    test_incoming['dispo'] = al_dis\n",
    "    test_incoming['dis_type'] = dispo_type\n",
    "    df_complete = pd.merge(test_incoming, test_tocompare, on='ID_Profile',how='left')\n",
    "    df_complete_merged = df_complete_merged.append(df_complete)\n",
    "#1111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111\n",
    "#print(count)           \n",
    "#df_complete_merged"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Cell number 16: The script below assigns 1 column for index number for the test. This index number is inherited from the original file df_main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_complete_merged['test_index'] = df_complete_merged['index_no'].astype(str) + df_complete_merged['index_no_x'].astype(str)\n",
    "df_complete_merged['test_index'] = df_complete_merged['test_index'].map(lambda x: x.lstrip('nan').rstrip('nan'))\n",
    "df_complete_merged=df_complete_merged.drop(columns=['index_no', 'index_no_x'])\n",
    "\n",
    "str2date(df_complete_merged, 'DT_Specimen_x')\n",
    "str2date(df_complete_merged, 'DT_Specimen_y')\n",
    "\n",
    "df_complete_merged['day_diff'] = pd.to_datetime(df_complete_merged['DT_Specimen_x']) - pd.to_datetime(df_complete_merged['DT_Specimen_y'])\n",
    "df_complete_merged['day_value'] = df_complete_merged['day_diff']/np.timedelta64(1,'D')\n",
    "#df_complete_merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Open     56\n",
       "Close    44\n",
       "Name: dispo, dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Open: NoM         50\n",
       "Close: 4f         41\n",
       "Open: 4f           3\n",
       "Close: TT_14d      3\n",
       "Open: PrevNoTx     1\n",
       "Open: NoC_NTT      1\n",
       "Open: SeroConv     1\n",
       "Name: algo_dispo, dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "5.a      50\n",
       "10.a1    41\n",
       "9.b1      3\n",
       "3.b       3\n",
       "6.b       1\n",
       "7.a       1\n",
       "10.b2     1\n",
       "Name: dis_type, dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_complete_merged['dispo'].value_counts()\n",
    "df_complete_merged['algo_dispo'].value_counts()\n",
    "df_complete_merged['dis_type'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Cell number 17 creates a CSV file for this dataset. Please replace 'ResultOfAlgorithm.csv' with a file path and name of your choice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell number 17\n",
    "df_complete_merged.to_csv(r'ResultOfAlgorithm.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Cell number 18: We join the dataset generated by the algorithm script (`df_complete_merged`) on the main dataset (`df_main`). `test_index` and `S_No` are the same index inherited from `df_main`. We conduct a left join on this index number of both datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell number 18\n",
    "df_comp_merged_co = df_complete_merged.copy()\n",
    "df_main_co = df_main.copy()\n",
    "\n",
    "df_comp_merged_co['S_No'] = df_comp_merged_co['S_No'].astype(str)\n",
    "df_main_co['S_No'] = df_main_co['S_No'].astype(str)\n",
    "df_joined = df_comp_merged_co.merge(df_main_co, left_on='test_index',right_on = 'S_No', how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Cell number 19 creates a CSV file for this dataset. Please replace 'AlgorithmMerged.csv' with a file path and name of your choice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell number 19\n",
    "df_joined.to_csv(r'AlgorithmMerged.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This is the end of the script for the algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Open     56\n",
       "Close    44\n",
       "Name: dispo, dtype: int64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Open: NoM         50\n",
       "Close: 4f         41\n",
       "Open: 4f           3\n",
       "Close: TT_14d      3\n",
       "Open: PrevNoTx     1\n",
       "Open: NoC_NTT      1\n",
       "Open: SeroConv     1\n",
       "Name: algo_dispo, dtype: int64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "5.a      50\n",
       "10.a1    41\n",
       "9.b1      3\n",
       "3.b       3\n",
       "6.b       1\n",
       "7.a       1\n",
       "10.b2     1\n",
       "Name: dis_type, dtype: int64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_complete_merged['dispo'].value_counts()\n",
    "df_complete_merged['algo_dispo'].value_counts()\n",
    "df_complete_merged['dis_type'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Disposition                                  algo_dispo    \n",
       "Administrative Closure OOJ                   Open: NoM          1\n",
       "Administrative Closure per Reactor Grid      Open: NoM         23\n",
       "Infected, Brought to Non-Standard Treatment  Open: NoM          1\n",
       "Infected, Brought to Treatment               Open: NoC_NTT      1\n",
       "                                             Open: NoM          5\n",
       "Infected, Not Treated                        Open: NoM          1\n",
       "                                             Open: PrevNoTx     1\n",
       "Located, Refused Examination                 Open: NoM          1\n",
       "Not Infected                                 Open: NoM          1\n",
       "Previously Treated for this Infection        Open: NoM         17\n",
       "Name: ID_Profile, dtype: int64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_complete_merged.groupby(['Disposition','algo_dispo'])[\"ID_Profile\"].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
